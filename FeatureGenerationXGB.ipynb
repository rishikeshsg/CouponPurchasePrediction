{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import datetime\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coupons_train=pd.read_csv(\"Translated_Data/coupon_list_train.csv\", parse_dates=[\"DISPFROM\",\"DISPEND\"])\n",
    "coupons_test = pd.read_csv(\"Translated_Data/coupon_list_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishikesh/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "coupons_train[\"DISPFROM\"].fillna(pd.Timestamp(\"19000101\"), inplace=True)\n",
    "coupons_train = coupons_train.sort(columns=[\"DISPFROM\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_validation(coupons_train,time_delta):\n",
    "    max_date = coupons_train[\"DISPFROM\"].max()\n",
    "    valid_start = max_date - time_delta\n",
    "    coupons_valid = coupons_train[(coupons_train[\"DISPFROM\"] > valid_start)]\n",
    "    coupons_train = coupons_train[~ (coupons_train[\"DISPFROM\"] > valid_start)]\n",
    "    return coupons_train,coupons_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coupons_train,coupons_valid=gen_validation(coupons_train,datetime.timedelta(days=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers(coupons_train,coupons_valid):\n",
    "    if len(coupons_valid)>0:\n",
    "        very_long_time_display=coupons_valid[coupons_valid.DISPPERIOD > 20].COUPON_ID_hash\n",
    "        very_low_price = coupons_valid[coupons_valid.DISCOUNT_PRICE <= 100].COUPON_ID_hash\n",
    "        coupons_valid = coupons_valid[~coupons_valid.COUPON_ID_hash.isin(very_long_time_display)]\n",
    "        coupons_valid = coupons_valid[~coupons_valid.COUPON_ID_hash.isin(very_low_price)].reset_index(drop=True)\n",
    "        \n",
    "    very_long_time_display = coupons_train[coupons_train.DISPPERIOD > 20].COUPON_ID_hash\n",
    "    coupons_train = coupons_train[~coupons_train.COUPON_ID_hash.isin(very_long_time_display)].reset_index(drop=True)\n",
    "    \n",
    "    return coupons_train,coupons_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coupons_train,coupons_valid=remove_outliers(coupons_train,coupons_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def preprocess(df):\n",
    "        df[\"REDUCE_PRICE\"] = df[\"CATALOG_PRICE\"] - df[\"DISCOUNT_PRICE\"]\n",
    "        for key in [\"DISCOUNT_PRICE\", \"CATALOG_PRICE\", \"REDUCE_PRICE\"]:\n",
    "            df[key + \"_LOG\"] = np.log(df[key] + 1.0).astype(np.float32)\n",
    "\n",
    "        df[\"VALIDPERIOD_NA\"] = np.array(pd.isnull(df[\"VALIDPERIOD\"]), dtype=np.int32)\n",
    "        df[\"DISPPERIOD_C\"] = np.array(df[\"DISPPERIOD\"].clip(0, 8), dtype=np.int32)\n",
    "        df[\"PRICE_RATE\"] = np.array(df.PRICE_RATE, dtype=np.float32)\n",
    "        df[\"large_area_name\"].fillna(\"NA\", inplace=True)\n",
    "        df[\"ken_name\"].fillna(\"NA\", inplace=True)\n",
    "        df[\"small_area_name\"].fillna(\"NA\", inplace=True)\n",
    "        df[\"LARGE_AREA_NAME\"] = df[\"large_area_name\"]\n",
    "        df[\"PREF_NAME\"] = df[\"large_area_name\"] + \":\" + df[\"ken_name\"]\n",
    "        df[\"SMALL_AREA_NAME\"] = df[\"large_area_name\"] + \":\" + df[\"ken_name\"] + \":\" + df[\"small_area_name\"]\n",
    "        df[\"CATEGORY_NAME\"] = df[\"CAPSULE_TEXT\"] + df[\"GENRE_NAME\"]\n",
    "\n",
    "        usable_dates = ['USABLE_DATE_MON',\n",
    "                        'USABLE_DATE_TUE',\n",
    "                        'USABLE_DATE_WED',\n",
    "                        'USABLE_DATE_THU',\n",
    "                        'USABLE_DATE_FRI',\n",
    "                        'USABLE_DATE_SAT',\n",
    "                        'USABLE_DATE_SUN',\n",
    "                        'USABLE_DATE_HOLIDAY',\n",
    "                        'USABLE_DATE_BEFORE_HOLIDAY']        \n",
    "        for key in usable_dates:\n",
    "            df[key].fillna(0, inplace=True)\n",
    "        df[\"USABLE_DATE_SUM\"] = 0\n",
    "        for key in usable_dates:\n",
    "            df[\"USABLE_DATE_SUM\"] += df[key]\n",
    "\n",
    "        cols = df.columns.tolist()\n",
    "        cols.remove(\"DISPFROM\")\n",
    "        cols.remove(\"DISPEND\")\n",
    "        for key in cols:\n",
    "            df[key].fillna(\"NA\", inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coupons_train=preprocess(coupons_train)\n",
    "coupons_valid=preprocess(coupons_valid)\n",
    "coupons_test=preprocess(coupons_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " coupon_mapper = DataFrameMapper([\n",
    "                ('CATEGORY_NAME', LabelBinarizer()),\n",
    "                ('PRICE_RATE', None),\n",
    "                ('CATALOG_PRICE_LOG', None),\n",
    "                ('DISCOUNT_PRICE_LOG', None),\n",
    "                ('REDUCE_PRICE_LOG', None),\n",
    "                ('DISPPERIOD_C', LabelBinarizer()),\n",
    "                ('VALIDPERIOD_NA', LabelBinarizer()),\n",
    "                ('USABLE_DATE_SUM', None),\n",
    "                ('LARGE_AREA_NAME', LabelBinarizer()),\n",
    "                ('PREF_NAME', LabelBinarizer()),\n",
    "                ('SMALL_AREA_NAME', LabelBinarizer()),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coupon_mapper.fit(pd.concat([coupons_train, coupons_valid, coupons_test]))\n",
    "train_coupon_vec = coupon_mapper.transform(coupons_train.copy())\n",
    "valid_coupon_vec = coupon_mapper.transform(coupons_valid.copy())\n",
    "test_coupon_vec = coupon_mapper.transform(coupons_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishikesh/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "user_frame = pd.read_csv(\"Translated_Data/user_list.csv\")\n",
    "details_frame = pd.read_csv(\"Translated_Data/coupon_detail_train.csv\",parse_dates=[\"I_DATE\"])\n",
    "details_frame = details_frame.sort(columns=[\"I_DATE\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_mapper = DataFrameMapper([\n",
    "                ('SEX_ID', LabelBinarizer()),\n",
    "                ('PREF_NAME', LabelBinarizer()),\n",
    "                ('AGE', None),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_frame[\"PREF_NAME\"].fillna(\"NA\", inplace=True)\n",
    "user_vec = user_mapper.fit_transform(user_frame.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishikesh/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:11: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/home/rishikesh/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:17: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "users = []\n",
    "coupons_train[\"ROW_ID\"] = pd.Series(coupons_train.index.tolist())\n",
    "coupons_valid[\"ROW_ID\"] = pd.Series(coupons_valid.index.tolist())\n",
    "\n",
    "for i, user in user_frame.iterrows():\n",
    "    coupons = details_frame[details_frame.USER_ID_hash.isin([user[\"USER_ID_hash\"]])]\n",
    "    train_coupon_data = pd.merge(coupons[[\"COUPON_ID_hash\",\"ITEM_COUNT\",\"I_DATE\"]],\n",
    "                                         coupons_train,\n",
    "                                         on=\"COUPON_ID_hash\", how='inner',\n",
    "                                         suffixes=[\"_x\",\"\"], copy=False)\n",
    "    train_coupon_data = train_coupon_data.sort(columns=[\"I_DATE\"])\n",
    "    row_ids = train_coupon_data.ROW_ID.unique().tolist()\n",
    "\n",
    "    valid_coupon_data = pd.merge(coupons[[\"COUPON_ID_hash\",\"ITEM_COUNT\",\"I_DATE\"]],\n",
    "                                         coupons_valid, on=\"COUPON_ID_hash\",\n",
    "                                         how='inner', suffixes=[\"_x\",\"\"], copy=False)\n",
    "    valid_coupon_data = valid_coupon_data.sort(columns=[\"I_DATE\"])\n",
    "    valid_row_ids = valid_coupon_data.ROW_ID.unique().tolist()\n",
    "\n",
    "    users.append({\"user\": user_vec[i],\n",
    "                    \"coupon_ids\": row_ids,\n",
    "                    \"valid_coupon_ids\": valid_row_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxmin_columns(coupons_train,coupon_ids):\n",
    "    return coupons_train.ix[\n",
    "        coupon_ids, (\"CATALOG_PRICE\",\"DISCOUNT_PRICE\")\n",
    "        ].as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def purchase_history_features(train_coupon_vec, user_coupon_vec, maxmin_columns, filter_idx=None):\n",
    "        sum_vec = np.zeros(2, dtype=np.float32)\n",
    "        maxmin_vec = np.zeros((4), dtype=np.float32)\n",
    "        mean_coupon_vec = np.zeros(len(train_coupon_vec[0]), dtype=np.float32)\n",
    "        \n",
    "        if filter_idx is not None:\n",
    "            if len(user_coupon_vec[filter_idx]) > 0:\n",
    "                mean_coupon_vec[:] = user_coupon_vec[filter_idx].mean(0)\n",
    "                sum_vec[0] = filter_idx.sum()\n",
    "                sum_vec[1] = np.log(sum_vec[0] + 1.0)\n",
    "                max_val = maxmin_columns[filter_idx].max(0)\n",
    "                min_val = maxmin_columns[filter_idx].min(0)\n",
    "                maxmin_vec[0] = max_val[0]\n",
    "                maxmin_vec[1] = min_val[0]\n",
    "                maxmin_vec[2] = max_val[1]\n",
    "                maxmin_vec[3] = min_val[1]\n",
    "        else:\n",
    "            if len(user_coupon_vec) > 0:\n",
    "                mean_coupon_vec = user_coupon_vec.mean(0)\n",
    "                sum_vec[0] = len(user_coupon_vec)\n",
    "                sum_vec[1] = np.log(sum_vec[0] + 1.0)\n",
    "                max_val = maxmin_columns.max(0)\n",
    "                min_val = maxmin_columns.min(0)\n",
    "                maxmin_vec[0] = max_val[0]\n",
    "                maxmin_vec[1] = min_val[0]\n",
    "                maxmin_vec[2] = max_val[1]\n",
    "                maxmin_vec[3] = min_val[1]\n",
    "\n",
    "        return np.hstack((mean_coupon_vec, sum_vec, maxmin_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COUPON_DISP_NEAR = 400\n",
    "COUPON_DISP_NEAR_MIN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_train_data(num_nega=2, verbose=True):\n",
    "        x = []\n",
    "        y = []\n",
    "        for user in users:\n",
    "            coupon_ids = np.array(user[\"coupon_ids\"], dtype=np.int32)\n",
    "            user_coupons = train_coupon_vec[coupon_ids]\n",
    "            maxmin_c = maxmin_columns(coupons_train,coupon_ids)\n",
    "            for i in xrange(len(user_coupons)):\n",
    "                target_coupon_vec = user_coupons[i]\n",
    "                rid = coupon_ids[i]\n",
    "                nega_list = range(max(0, rid - COUPON_DISP_NEAR), rid)\n",
    "                if len(nega_list) < COUPON_DISP_NEAR_MIN:\n",
    "                    continue\n",
    "\n",
    "                filter_idx = np.ones(user_coupons.shape[0], dtype=np.bool)\n",
    "                \n",
    "                # exclude coupons that was purchased after the target coupon\n",
    "                filter_idx[i:] = False\n",
    "                # exclude the target coupon (and remove duplicate)\n",
    "                filter_idx[coupon_ids == coupon_ids[i]] = False\n",
    "                \n",
    "                hist_feat = purchase_history_features(train_coupon_vec,user_coupons,\n",
    "                                                             maxmin_c,\n",
    "                                                             filter_idx)\n",
    "                # feature vector (user_feature + purchase_history_feature + coupon_feature)\n",
    "                purchased_feat = np.hstack((user[\"user\"], hist_feat, target_coupon_vec))\n",
    "                x.append(purchased_feat)\n",
    "                y.append([1]) # posi\n",
    "\n",
    "                # select random unpurchased coupons\n",
    "                for j in xrange(num_nega):\n",
    "                    found = False\n",
    "                    for _ in xrange(10):\n",
    "                        unpurchased_idx = np.random.choice(nega_list, 1)[0]\n",
    "                        if unpurchased_idx not in user[\"coupon_ids\"]:\n",
    "                            found = True\n",
    "                            break\n",
    "                    if found:\n",
    "                        unpurchased_feat = np.hstack((user[\"user\"],\n",
    "                                                      hist_feat,\n",
    "                                                      train_coupon_vec[unpurchased_idx]))\n",
    "                        x.append(unpurchased_feat)\n",
    "                        y.append([0]) # nega\n",
    "\n",
    "        x = np.array(x, dtype=np.float32)\n",
    "        y = np.array(y, dtype=np.int32)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_valid_data(num_nega=5, verbose=True):\n",
    "        x = []\n",
    "        y = []\n",
    "        for user in users:\n",
    "            coupon_ids = np.array(user[\"coupon_ids\"], dtype=np.int32)\n",
    "            user_coupons = train_coupon_vec[coupon_ids]\n",
    "            valid_coupon_ids=np.array(user[\"valid_coupon_ids\"], dtype=np.int32)\n",
    "            valid_user_coupons=valid_coupon_vec[valid_coupon_ids]\n",
    "            maxmin_c = maxmin_columns(coupons_train,coupon_ids)\n",
    "            hist_feat = purchase_history_features(train_coupon_vec, user_coupons, maxmin_c)\n",
    "            \n",
    "            for i in xrange(len(valid_user_coupons)):\n",
    "                target_coupon_vec = valid_user_coupons[i]\n",
    "                #rid = coupon_ids[i]\n",
    "                \n",
    "                # feature vector (user_feature + purchase_history_feature + coupon_feature)\n",
    "                purchased_feat = np.hstack((user[\"user\"], hist_feat, target_coupon_vec))\n",
    "                x.append(purchased_feat)\n",
    "                y.append(1) # posi\n",
    "\n",
    "                # select random unpurchased coupons\n",
    "                for j in xrange(num_nega):\n",
    "                    found = False\n",
    "                    for _ in xrange(10):\n",
    "                        unpurchased_idx = np.random.choice(range(len(valid_coupon_vec)), 1)[0]\n",
    "                        if unpurchased_idx not in user[\"valid_coupon_ids\"]:\n",
    "                            found = True\n",
    "                            break\n",
    "                    if found:\n",
    "                        unpurchased_feat = np.hstack((user[\"user\"],\n",
    "                                                      hist_feat,\n",
    "                                                      valid_coupon_vec[unpurchased_idx]))\n",
    "                        x.append(unpurchased_feat)\n",
    "                        y.append(0) # nega\n",
    "\n",
    "        x = np.array(x, dtype=np.float32)\n",
    "        y = np.array(y, dtype=np.int32)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feature,train_label=gen_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_feature,valid_label=gen_valid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgboost.DMatrix(train_feature, label = train_label)\n",
    "dvalid = xgboost.DMatrix(valid_feature, label = valid_label)\n",
    "param = {'max_depth':7, 'eta':0.05, 'objective':'binary:logistic', 'subsample':0.9, 'colsample_bytree':0.5, \n",
    "         'metric':'auc'}\n",
    "watchlist  = [(dvalid,'eval'), (dtrain,'train')]\n",
    "num_rounds=1500\n",
    "bst = xgboost.train(param, dtrain, num_rounds, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_predictions={}\n",
    "def predict_for_test() :\n",
    "    test_user_coupons=test_coupon_vec\n",
    "    user_id=0\n",
    "    for user in users:\n",
    "        coupon_ids = np.array(user[\"coupon_ids\"], dtype=np.int32)\n",
    "        user_coupons = train_coupon_vec[coupon_ids]\n",
    "        maxmin_c = maxmin_columns(coupons_train,coupon_ids)\n",
    "        hist_feat = purchase_history_features(train_coupon_vec, user_coupons, maxmin_c)\n",
    "        \n",
    "        user_feat=np.hstack((user[\"user\"],hist_feat))\n",
    "        user_feat_rep=np.array([list(user_feat)]*len(test_coupon_vec))\n",
    "        purchased_feats=np.hstack((user_feat_rep,test_coupon_vec))\n",
    "        \n",
    "        dtest = xgboost.DMatrix(purchased_feats)\n",
    "        conf_predicted=bst.predict(dtest)\n",
    "        \n",
    "        conf_predicted=[(conf_predicted[i],i) for i in range(len(conf_predicted))]\n",
    "        conf_predicted.sort()\n",
    "        top10=[i for (c,i) in conf_predicted[-10:]]\n",
    "        \n",
    "        user_predictions[user_frame['USER_ID_hash'][user_id]]=[coupons_test['COUPON_ID_hash'][i] for i in top10]\n",
    "        user_id+=1\n",
    "        if user_id%1000==0:\n",
    "            print user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n"
     ]
    }
   ],
   "source": [
    "predict_for_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2799a41a862fed399ae7ca699c83f3a3', '3d5c0b4c9e35377c0df5e1e7efe1da42', 'c9e1dcbd8c98f919bf85ab5f2ea30a9d', '42cc500acba3c79883cfd40adcd5ae96', 'f1f00137ca89c6bb32f366ef5f66a001', '2af19a2244a2c2466b87b98e065cdfa7', 'ca8ea3d52ca939d6ab1b9c792baa6169', 'd79a889ee9d0712607a2672e96ba3d69', '27741884a086e2864936d7ef680becc2', '5e47b887e154f746883013f863c3ffe1']\n",
      "['7ae4e60eab2e4d7e20f88fc19267e87c', '7c9eb3afbf373124bbe21f80b38f413a', '1bad24bc593914e7970f4ae2fb94c203', '625f1962d2c6b55c5f61def56a49dd21', 'd4e29fa02359c30bedc401ea197ce6a2', '529fa18083e92247ea20e877d5b5bb16', '00fcc93438a282f8b915777a209dd0bd', '3810431a7769cfcc3201383b5e83248c', '300d583837219793a0fbb9cb5844bd24', '27741884a086e2864936d7ef680becc2']\n"
     ]
    }
   ],
   "source": [
    "print user_predictions[user_predictions.keys()[0]]\n",
    "print user_predictions[user_predictions.keys()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output.csv', 'w') as f:\n",
    "    f.write('USER_ID_hash,PURCHASED_COUPONS\\n')\n",
    "    for user in user_predictions.keys():\n",
    "        f.write(user+','+' '.join(user_predictions[user])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in user_predictions.keys():\n",
    "    base=user_predictions[user]\n",
    "    break\n",
    "for user in user_predictions.keys():\n",
    "    if user_predictions[user]!=base:\n",
    "        print \"Mismatch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:2: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: FutureWarning: sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This Series is a view of some other array, to sort in-place you must create a copy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-bab7878604ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0muf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0muf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'USER_ID_hash'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0muf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'USER_ID_hash'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#uf=user_frame['USER_ID_hash']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#uf.sort(user_frame.copy())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36msort\u001b[1;34m(self, axis, ascending, kind, na_position, inplace)\u001b[0m\n\u001b[0;32m   1808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m         return self.sort_values(ascending=ascending, kind=kind,\n\u001b[1;32m-> 1810\u001b[1;33m                                 na_position=na_position, inplace=inplace)\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m     def order(self, na_last=None, ascending=True, kind='quicksort',\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[0;32m   1707\u001b[0m         \u001b[1;31m# GH 5856/5853\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_cached\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1709\u001b[1;33m             raise ValueError(\"This Series is a view of some other array, to \"\n\u001b[0m\u001b[0;32m   1710\u001b[0m                              \"sort in-place you must create a copy\")\n\u001b[0;32m   1711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This Series is a view of some other array, to sort in-place you must create a copy"
     ]
    }
   ],
   "source": [
    "uf=user_frame.copy()\n",
    "uf.sort(columns=['USER_ID_hash'])\n",
    "uf['USER_ID_hash'].sort()\n",
    "#uf=user_frame['USER_ID_hash']\n",
    "#uf.sort(user_frame.copy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
